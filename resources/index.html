<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Resources - Myreze-Labs: Depth Estimation</title>
    <link rel="stylesheet" href="../css/main.css">
    <link rel="stylesheet" href="../css/theme.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body class="resources-page">
    <header>
        <div class="logo-container">
            <img src="../images/myreze_logo.svg" alt="Myreze Logo" class="logo-small">
        </div>
        <h1>Resources</h1>
        <a href="../hub.html" class="back-button"><i class="fas fa-arrow-left"></i> Back to Hub</a>
    </header>

    <main>
        <section class="resource-section">
            <h2><i class="fas fa-cube"></i> ComfyUI Resources</h2>
            <div class="resource-cards">
                <a href="https://www.comfy.org/download" target="_blank" class="resource-card">
                    <h3>ComfyUI Installation</h3>
                    <p>Official download and installation guide for ComfyUI</p>
                    <span class="resource-link"><i class="fas fa-download"></i> Install</span>
                </a>
                <a href="https://github.com/Comfy-Org/ComfyUI-Manager" target="_blank" class="resource-card">
                    <h3>ComfyUI Manager</h3>
                    <p>Tool for managing ComfyUI models and extensions</p>
                    <span class="resource-link"><i class="fas fa-cogs"></i> Manage Models</span>
                </a>
                <a href="https://comfyanonymous.github.io/ComfyUI_examples/" target="_blank" class="resource-card">
                    <h3>ComfyUI Examples</h3>
                    <p>Getting started with ComfyUI workflows</p>
                    <span class="resource-link"><i class="fas fa-play"></i> Start Learning</span>
                </a>
            </div>
        </section>

        <section class="resource-section">
            <h2><i class="fas fa-layer-group"></i> Depth Estimation Extensions</h2>
            <p class="section-intro">The following extensions enable different depth estimation capabilities in ComfyUI:</p>
            
            <div class="resource-table-container">
                <table class="resource-table">
                    <thead>
                        <tr>
                            <th>Extension/Node</th>
                            <th>Underlying Model</th>
                            <th>Key Features</th>
                            <th>Use Case Example</th>
                            <th>Installation</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ComfyUI-depth-fm</td>
                            <td>DepthFM</td>
                            <td>Fast, single-step, versatile</td>
                            <td>Quick depth maps for real-time apps</td>
                            <td><a href="https://github.com/kijai/ComfyUI-depth-fm" target="_blank"><i class="fab fa-github"></i> Install</a></td>
                        </tr>
                        <tr>
                            <td>ComfyUI-DepthAnythingV2</td>
                            <td>Depth Anything V2</td>
                            <td>Fine-grained, robust, efficient</td>
                            <td>Detailed 3D effects in digital art</td>
                            <td><a href="https://github.com/yuvraj108c/ComfyUI-Depth-Anything-Tensorrt" target="_blank"><i class="fab fa-github"></i> Install</a></td>
                        </tr>
                        <tr>
                            <td>ComfyUI-Marigold</td>
                            <td>Marigold</td>
                            <td>Detailed, flexible, eliminates biases</td>
                            <td>High-quality depth for VFX/3D modeling</td>
                            <td><a href="https://github.com/kijai/ComfyUI-Marigold" target="_blank"><i class="fab fa-github"></i> Install</a></td>
                        </tr>
                        <tr>
                            <td>ComfyUI-Depth-Pro</td>
                            <td>ML-Depth-Pro</td>
                            <td>Advanced, high-resolution</td>
                            <td>Enhanced depth perception in UI</td>
                            <td><a href="https://github.com/spacepxl/ComfyUI-Depth-Pro" target="_blank"><i class="fab fa-github"></i> Install</a></td>
                        </tr>
                        <tr>
                            <td>ComfyUIDepthEstimation</td>
                            <td>Transformer models</td>
                            <td>Gamma correction, contrast, edge detection</td>
                            <td>Enhanced depth maps with post-processing</td>
                            <td><a href="https://comfyanonymous.github.io/ComfyUI_examples/stable_cascade/" target="_blank"><i class="fab fa-github"></i> Install</a></td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <p class="table-note">Installation: Click the GitHub links to access the repositories. Most extensions can be installed by cloning into the ComfyUI custom_nodes directory.</p>
        </section>
        
        <!-- New 2D to 3D Resources Section -->
        <section class="resource-section">
            <h2><i class="fas fa-cube"></i> 2D to 3D Generative AI Resources</h2>
            <p class="section-intro">State-of-the-art models and tools for generating 3D content from 2D inputs:</p>
            
            <div class="resource-table-container">
                <table class="resource-table large-table">
                    <thead>
                        <tr>
                            <th>Name</th>
                            <th>Organization</th>
                            <th>Year</th>
                            <th>Links</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>GEN3C</td>
                            <td>NVIDIA Research, Toronto AI Lab</td>
                            <td>2025</td>
                            <td class="links-cell">
                                <a href="https://research.nvidia.com/labs/toronto-ai/GEN3C/" target="_blank"><i class="fas fa-external-link-alt"></i> Project</a>
                                <a href="https://arxiv.org/abs/2503.03751" target="_blank"><i class="fas fa-file-alt"></i> Paper</a>
                            </td>
                            <td>A generative video model with precise Camera Control and temporal 3D Consistency using a 3D cache of point clouds.</td>
                        </tr>
                        
                        <tr>
                            <td>Hi3DGen</td>
                            <td>CUHK (Shenzhen), ByteDance, Tsinghua University</td>
                            <td>2025</td>
                            <td class="links-cell">
                                <a href="https://stable-x.github.io/Hi3DGen/" target="_blank"><i class="fas fa-external-link-alt"></i> Project</a>
                                <a href="https://github.com/Stable-X/Hi3DGen" target="_blank"><i class="fab fa-github"></i> GitHub</a>
                                <a href="https://huggingface.co/spaces/Stable-X/Hi3DGen" target="_blank"><i class="fas fa-play-circle"></i> Demo</a>
                            </td>
                            <td>A framework for generating high-fidelity 3D geometry from images via normal bridging.</td>
                        </tr>
                        
                        <tr>
                            <td>Hunyuan3D 2.0</td>
                            <td>Tencent</td>
                            <td>2025</td>
                            <td class="links-cell">
                                <a href="https://www.hunyuan-3d.com/" target="_blank"><i class="fas fa-external-link-alt"></i> Project</a>
                                <a href="https://github.com/Tencent/Hunyuan3D-2" target="_blank"><i class="fab fa-github"></i> GitHub</a>
                                <a href="https://huggingface.co/tencent/Hunyuan3D-2" target="_blank"><i class="fas fa-cube"></i> Model</a>
                            </td>
                            <td>An advanced large-scale 3D synthesis system for generating high-resolution textured 3D assets.</td>
                        </tr>
                        
                        <tr>
                            <td>Stable Virtual Camera (Seva)</td>
                            <td>Stability AI</td>
                            <td>2025</td>
                            <td class="links-cell">
                                <a href="https://stable-virtual-camera.github.io/" target="_blank"><i class="fas fa-external-link-alt"></i> Project</a>
                                <a href="https://github.com/Stability-AI/stable-virtual-camera" target="_blank"><i class="fab fa-github"></i> GitHub</a>
                                <a href="https://arxiv.org/abs/2503.14489" target="_blank"><i class="fas fa-file-alt"></i> Paper</a>
                            </td>
                            <td>A 1.3B generalist diffusion model for Novel View Synthesis, generating 3D consistent novel views of a scene.</td>
                        </tr>
                        
                        <tr>
                            <td>DreamFusion</td>
                            <td>Google Research, UC Berkeley</td>
                            <td>2022</td>
                            <td class="links-cell">
                                <a href="https://dreamfusion3d.github.io/" target="_blank"><i class="fas fa-external-link-alt"></i> Project</a>
                                <a href="https://github.com/ashawkey/stable-dreamfusion" target="_blank"><i class="fab fa-github"></i> GitHub</a>
                                <a href="https://arxiv.org/abs/2209.14988" target="_blank"><i class="fas fa-file-alt"></i> Paper</a>
                            </td>
                            <td>A text-to-3D synthesis method using pretrained 2D diffusion models without requiring 3D training data.</td>
                        </tr>
                        
                        <tr>
                            <td>Zero-1-to-3</td>
                            <td>Columbia University, Toyota Research Institute</td>
                            <td>2023</td>
                            <td class="links-cell">
                                <a href="https://zero123.cs.columbia.edu/" target="_blank"><i class="fas fa-external-link-alt"></i> Project</a>
                                <a href="https://github.com/cvlab-columbia/zero123" target="_blank"><i class="fab fa-github"></i> GitHub</a>
                                <a href="https://huggingface.co/spaces/cvlab/zero123-live" target="_blank"><i class="fas fa-play-circle"></i> Demo</a>
                            </td>
                            <td>A framework for changing the camera viewpoint of an object given just a single RGB image.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            
            <p class="table-note">Note: These resources represent the current state-of-the-art in 2D to 3D generation and may require significant computational resources.</p>
        </section>

        <section class="resource-section">
            <h2><i class="fas fa-book"></i> Documentation</h2>
            <div class="resource-cards">
                <a href="https://github.com/comfyanonymous/ComfyUI" target="_blank" class="resource-card">
                    <h3>ComfyUI Documentation</h3>
                    <p>Official documentation for ComfyUI</p>
                    <span class="resource-link"><i class="fas fa-external-link-alt"></i> Visit</span>
                </a>
                <a href="https://pytorch.org/docs/stable/index.html" target="_blank" class="resource-card">
                    <h3>PyTorch Documentation</h3>
                    <p>Official documentation for PyTorch</p>
                    <span class="resource-link"><i class="fas fa-external-link-alt"></i> Visit</span>
                </a>
            </div>
        </section>

        <section class="resource-section">
            <h2><i class="fas fa-video"></i> Tutorials</h2>
            <div class="resource-cards">
                <a href="https://www.youtube.com/watch?v=example1" target="_blank" class="resource-card">
                    <h3>Depth Estimation Basics</h3>
                    <p>Introduction to depth estimation concepts</p>
                    <span class="resource-link"><i class="fab fa-youtube"></i> Watch</span>
                </a>
                <a href="https://www.youtube.com/watch?v=example2" target="_blank" class="resource-card">
                    <h3>ComfyUI for Beginners</h3>
                    <p>Getting started with ComfyUI</p>
                    <span class="resource-link"><i class="fab fa-youtube"></i> Watch</span>
                </a>
            </div>
        </section>

        <section class="resource-section">
            <h2><i class="fas fa-link"></i> Useful Links</h2>
            <div class="resource-cards">
                <a href="https://github.com/FeiGeChuanShu/ComfyUI-depth-fm" target="_blank" class="resource-card">
                    <h3>ComfyUI-depth-fm</h3>
                    <p>GitHub repository for ComfyUI-depth-fm</p>
                    <span class="resource-link"><i class="fab fa-github"></i> Visit</span>
                </a>
                <a href="https://github.com/lllyasviel/ControlNet" target="_blank" class="resource-card">
                    <h3>ControlNet</h3>
                    <p>GitHub repository for ControlNet</p>
                    <span class="resource-link"><i class="fab fa-github"></i> Visit</span>
                </a>
                <a href="https://github.com/isl-org/MiDaS" target="_blank" class="resource-card">
                    <h3>MiDaS</h3>
                    <p>GitHub repository for MiDaS depth estimation</p>
                    <span class="resource-link"><i class="fab fa-github"></i> Visit</span>
                </a>
            </div>
        </section>

        <section class="resource-section">
            <h2><i class="fas fa-download"></i> Downloads</h2>
            <div class="resource-cards">
                <a href="#" class="resource-card">
                    <h3>Workshop Materials</h3>
                    <p>Downloadable materials from the workshop</p>
                    <span class="resource-link"><i class="fas fa-download"></i> Download</span>
                </a>
                <a href="#" class="resource-card">
                    <h3>Example Projects</h3>
                    <p>Sample projects to get started</p>
                    <span class="resource-link"><i class="fas fa-download"></i> Download</span>
                </a>
            </div>
        </section>
    </main>

    <footer>
        <p>&copy; 2023 Myreze-Labs. All rights reserved.</p>
    </footer>

    <script src="../js/main.js"></script>
</body>
</html> 